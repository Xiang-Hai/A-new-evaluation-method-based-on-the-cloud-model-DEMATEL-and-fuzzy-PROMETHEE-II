{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d009e8f4",
   "metadata": {},
   "source": [
    "Source code for our research ....\n",
    "\n",
    "The main code include two parts, which are Cloud model-DEMATEL and Fuzzy based PROMETHEE II."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fb53d450",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load modules\n",
    "import pandas as pd\n",
    "import warnings\n",
    "import numpy as np\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d5efd64",
   "metadata": {},
   "source": [
    "## Cloud model-DEMATEL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "260400d2",
   "metadata": {},
   "source": [
    "### Define the Convert_LIT_to_CloudModel function to convert user evaluation linguistic to cloud model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e8d71812",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Convert_LIT_to_CloudModel(assessment_matrix):\n",
    "    '''\n",
    "    input:\n",
    "        evaluation_matrix: linguistic term assessment matrix provided by user,\n",
    "                           size: n×n\n",
    "    output:\n",
    "        C_Ex: the expectation of cloud model, size: n×n\n",
    "        C_En: the entropy of cloud model, size: n×n\n",
    "        C_He: the super-entropy of cloud model, size: n×n\n",
    "    Reference: Identifying critical causal criteria of green supplier evaluation\n",
    "               using heterogeneous judgements: An integrated approach based on cloud\n",
    "               model and DEMATEL\n",
    "    '''\n",
    "    # 有效域:[X_min,X_max] = [0,10]\n",
    "    # 语言项集：S = {s_-2,s_-1,s_0,s_1,s_2}\n",
    "    linguistic_term_table = {'s-2':(0,2.85,0.16),\n",
    "                             's-1':(2.92,2.45,0.29),\n",
    "                             's0': (5,2.13,0.40),\n",
    "                             's1': (7.08,2.45,0.29),\n",
    "                             's2': (10,2.85,0.16)}\n",
    "    C_Ex = np.zeros(assessment_matrix.shape)\n",
    "    C_En = np.zeros(assessment_matrix.shape)\n",
    "    C_He = np.zeros(assessment_matrix.shape)\n",
    "    for i in range(assessment_matrix.shape[0]):\n",
    "        for j in range(assessment_matrix.shape[1]):\n",
    "            if i == j:\n",
    "                C_Ex[i][j] = 0\n",
    "                C_En[i][j] = 0\n",
    "                C_He[i][j] = 0\n",
    "            else:\n",
    "                assessment_value_ij = assessment_matrix[i][j]\n",
    "                cloud_model_ij = linguistic_term_table[assessment_value_ij]\n",
    "                C_Ex[i][j] = cloud_model_ij[0]\n",
    "                C_En[i][j] = cloud_model_ij[1]\n",
    "                C_He[i][j] = cloud_model_ij[2]\n",
    "    return C_Ex,C_En,C_He"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ea4dbed",
   "metadata": {},
   "source": [
    "### Weight calculation methods of DEMATEL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ed4f6a2",
   "metadata": {},
   "source": [
    "#### Method proposed by Cebi (2013)\n",
    "\n",
    "Reference: Cebi, S. (2013). **Determining importance degrees of website design parameters based on interactions and types of websites**. Decision Support Systems, 54(2), 1030-1043. https://doi.org/10.1016/j.dss.2012.10.036"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d131919b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def weight_by_Cebi_method(P_L,P_U):\n",
    "    P_mean = (P_L + P_U)/2\n",
    "    weight = P_mean/sum(P_mean)\n",
    "    return np.around(weight,4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eb5f5d2",
   "metadata": {},
   "source": [
    "#### Method proposed by Wang (2015)\n",
    "\n",
    "Reference: Wang, C. (2015).**Using quality function deployment to conduct vendor assessment and supplier recommendation for business-intelligence systems.** Computers & Industrial Engineering,84,24-31.https://doi.org/10.1016/j.cie.2014.10.005"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e2061403",
   "metadata": {},
   "outputs": [],
   "source": [
    "def weight_by_Wang_method(R_L,R_U):\n",
    "    abs_R = np.abs((R_L+R_U)/2)\n",
    "    weight = abs_R/sum(abs_R)\n",
    "    return np.around(weight,4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1699bd9f",
   "metadata": {},
   "source": [
    "#### Method proposed by Zhou et al. (2023)\n",
    "\n",
    "Reference: Zhou,T.,et al. (2023). **Smart experience-oriented customer requirement analysis for smart product service system A novel hesitant fuzzy linguistic cloud DEMATEL method.** Advanced Engineering Informatics, 56, 101917.https://doi.org/10.1016/j.aei.2023.101917"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1b9d189a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def weight_by_Zhou_method(P_L,P_U,P_Ex,R_L,R_U,R_Ex):\n",
    "    PL_REx = np.power(P_L,2) + np.power(R_Ex,2)\n",
    "    PU_REx = np.power(P_U,2) + np.power(R_Ex,2)\n",
    "    RL_PEx = np.power(R_L,2) + np.power(P_Ex,2)\n",
    "    RU_PEx = np.power(R_U,2) + np.power(P_Ex,2)\n",
    "    L = (np.sqrt(PL_REx) + np.sqrt(PU_REx) + np.sqrt(RL_PEx) + np.sqrt(RU_PEx))/4\n",
    "    weight = L/sum(L)\n",
    "    return np.around(weight,4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2f3c98f",
   "metadata": {},
   "source": [
    "#### Method proposed in this paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8663b010",
   "metadata": {},
   "outputs": [],
   "source": [
    "def weight_by_our_method(P_L,P_U,R_L,R_U):\n",
    "    combined_mean_value = (P_L + P_U + R_L + R_U)/4\n",
    "    weight = combined_mean_value/sum(combined_mean_value)\n",
    "    return np.around(weight,4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69b6ff7b",
   "metadata": {},
   "source": [
    "### Define the Cloud_DEMATEL function to calculate the preference weight of user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5a59bdf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ranking(input_values):\n",
    "    idx = np.argsort(-input_values)\n",
    "    ranking = np.zeros(input_values.shape)\n",
    "    for i in range(input_values.shape[0]):\n",
    "        ranking[idx[i]] = i+1\n",
    "    return ranking\n",
    "\n",
    "def Cloud_DEMATEL(input=None):\n",
    "    # S7.2. Convert user preference assessment matrix to preference cloud matrix\n",
    "    C_Ex, C_En, C_He = Convert_LIT_to_CloudModel(input) # sizes of C_Ex, C_En and C_He are n×n\n",
    "    \n",
    "    # S7.3. Calculate the normalized preference cloud matrix\n",
    "    sum_of_row = np.sum(C_Ex, axis=1)\n",
    "    sum_of_col = np.sum(C_Ex, axis=0)\n",
    "    s = max(max(sum_of_row),max(sum_of_col))\n",
    "    C_Ex_N = C_Ex/s\n",
    "    C_En_N = C_En/s\n",
    "    C_He_N = C_He/s\n",
    "    \n",
    "    # S7.4. Calculate the total preference cloud matrix\n",
    "    I = np.identity(C_Ex_N.shape[0])\n",
    "    T_Ex = C_Ex_N * np.linalg.inv(I - C_Ex_N)\n",
    "    T_En = C_En_N * np.linalg.inv(I - C_En_N)\n",
    "    T_He = C_He_N * np.linalg.inv(I - C_He_N)\n",
    "    \n",
    "    # S7.5. Calculate the prominence and relation\n",
    "    # calculate the sum of rows of T_Ex/T_En/T_He\n",
    "    SR_Ex = np.zeros(T_Ex.shape[0])\n",
    "    SR_En = np.zeros(T_En.shape[0])\n",
    "    SR_He = np.zeros(T_He.shape[0])\n",
    "    for i in range(T_Ex.shape[0]):\n",
    "        tmp_SR_Ex = 0.\n",
    "        tmp_SR_En = 0.\n",
    "        tmp_SR_He = 0.\n",
    "        for j in range(T_Ex.shape[1]):\n",
    "            tmp_SR_Ex += T_Ex[i,j]\n",
    "            tmp_SR_En += np.power(T_En[i,j],2)\n",
    "            tmp_SR_He += np.power(T_He[i,j],2)\n",
    "        SR_Ex[i] = tmp_SR_Ex\n",
    "        SR_En[i] = np.sqrt(tmp_SR_En)\n",
    "        SR_He[i] = np.sqrt(tmp_SR_He)\n",
    "    # calculate the sum of columns of T_Ex/T_En/T_He\n",
    "    SC_Ex = np.zeros(T_Ex.shape[1])\n",
    "    SC_En = np.zeros(T_En.shape[1])\n",
    "    SC_He = np.zeros(T_He.shape[1])\n",
    "    for j in range(T_Ex.shape[1]):\n",
    "        tmp_SC_Ex = 0.\n",
    "        tmp_SC_En = 0.\n",
    "        tmp_SC_He = 0.\n",
    "        for i in range(T_Ex.shape[0]):\n",
    "            tmp_SC_Ex += T_Ex[i,j]\n",
    "            tmp_SC_En += np.power(T_En[i,j],2)\n",
    "            tmp_SC_He += np.power(T_He[i,j],2)\n",
    "        SC_Ex[j] = tmp_SC_Ex\n",
    "        SC_En[j] = np.sqrt(tmp_SC_En)\n",
    "        SC_He[j] = np.sqrt(tmp_SC_He)\n",
    "    # calculate the prominence (P)\n",
    "    P_Ex = np.zeros(SR_Ex.shape)\n",
    "    P_En = np.zeros(SR_En.shape)\n",
    "    P_He = np.zeros(SR_He.shape)\n",
    "    for i in range(SC_Ex.shape[0]):\n",
    "        P_Ex[i] = SR_Ex[i] + SC_Ex[i]\n",
    "        P_En[i] = np.sqrt(np.power(SR_En[i],2) + np.power(SC_En[i],2))\n",
    "        P_He[i] = np.sqrt(np.power(SR_He[i],2) + np.power(SC_He[i],2))\n",
    "    # calculate the relation (R)\n",
    "    R_Ex = np.zeros(SR_Ex.shape)\n",
    "    R_En = np.zeros(SR_En.shape)\n",
    "    R_He = np.zeros(SR_He.shape)\n",
    "    for i in range(SC_Ex.shape[0]):\n",
    "        R_Ex[i] = SR_Ex[i] - SC_Ex[i]\n",
    "        R_En[i] = np.sqrt(np.power(SR_En[i],2) + np.power(SC_En[i],2))\n",
    "        R_He[i] = np.sqrt(np.power(SR_He[i],2) + np.power(SC_He[i],2))\n",
    "    \n",
    "    # S7.6. Calculate user preference weights\n",
    "    # calculate P_L and P_U\n",
    "    P_L = np.zeros(P_Ex.shape)\n",
    "    P_U = np.zeros(P_Ex.shape)\n",
    "    P = np.around(P_Ex,4)\n",
    "    for i in range(P_Ex.shape[0]):\n",
    "        P_L[i] = P_Ex[i] - 3*P_En[i] - 9*P_He[i]\n",
    "        P_U[i] = P_Ex[i] + 3*P_En[i] + 9*P_He[i]\n",
    "    # calculate R_L and R_U\n",
    "    R_L = np.zeros(R_Ex.shape)\n",
    "    R_U = np.zeros(R_Ex.shape)\n",
    "    R = np.around(R_Ex,4)\n",
    "    for i in range(R_Ex.shape[0]):\n",
    "        R_L[i] = R_Ex[i] - 3*R_En[i] - 9*R_He[i]\n",
    "        R_U[i] = R_Ex[i] + 3*R_En[i] + 9*R_He[i]\n",
    "        \n",
    "    # calculate weight\n",
    "    weights_by_Cebi = weight_by_Cebi_method(P_L,P_U)\n",
    "    weights_by_Wang = weight_by_Wang_method(R_L,R_U)\n",
    "    weights_by_Zhou = weight_by_Zhou_method(P_L,P_U,P_Ex,R_L,R_U,R_Ex)\n",
    "    weights_by_our_method = weight_by_our_method(P_L,P_U,R_L,R_U)\n",
    "    \n",
    "    return [P,R],[weights_by_Cebi,weights_by_Wang,weights_by_Zhou,weights_by_our_method]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7495da2d",
   "metadata": {},
   "source": [
    "## Fuzzy based PROMETHEE II"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feb95e55",
   "metadata": {},
   "source": [
    "### Preference function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c346e2ca",
   "metadata": {},
   "source": [
    "#### Type 1: Usual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "de99267a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Preference_Function_Type1(x):\n",
    "    if x <= 0:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26849632",
   "metadata": {},
   "source": [
    "#### Type 2: U-shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2f3acad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Preference_Function_Type2(x):\n",
    "    q = 0.5\n",
    "    if x <= q:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "217bcb5b",
   "metadata": {},
   "source": [
    "#### Type 3: V-shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "72fd618c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Preference_Function_Type3(x):\n",
    "    p = 0.5\n",
    "    if x <= 0:\n",
    "        return 0\n",
    "    elif x > p:\n",
    "        return 1\n",
    "    else:\n",
    "        return x/p"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "543ed3d3",
   "metadata": {},
   "source": [
    "#### Type 4: Level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "01b6aca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Preference_Function_Type4(x):\n",
    "    q = 0.5\n",
    "    p = 1\n",
    "    if x <= q:\n",
    "        return 0\n",
    "    elif x > p:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3119b6e",
   "metadata": {},
   "source": [
    "#### Type 5: V-shape with indifference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f27367c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Preference_Function_Type5(x):\n",
    "    q = 0.5\n",
    "    p = 1\n",
    "    if x <= q:\n",
    "        return 0\n",
    "    elif x > p:\n",
    "        return 1\n",
    "    else:\n",
    "        return (x-q)/(x-p)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8c7e85a",
   "metadata": {},
   "source": [
    "#### Type 6: Gaussian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8956e368",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Preference_Function_Type6(x):\n",
    "    s = 0.5\n",
    "    if x <= 0:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1 - np.exp(-np.power(x,2)/np.power(s,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "462ac8c5",
   "metadata": {},
   "source": [
    "### Define the Calculate_PF function to calculate the preference value according to the specified function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bfa8ece3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Calculate_PF(d,C_PF_type):\n",
    "    if C_PF_type == 'PF_type1':\n",
    "        return Preference_Function_Type1(d)\n",
    "    elif C_PF_type == 'PF_type2':\n",
    "        return Preference_Function_Type2(d)\n",
    "    elif C_PF_type == 'PF_type3':\n",
    "        return Preference_Function_Type3(d)\n",
    "    elif C_PF_type == 'PF_type4':\n",
    "        return Preference_Function_Type4(d)\n",
    "    elif C_PF_type == 'PF_type5':\n",
    "        return Preference_Function_Type5(d)\n",
    "    elif C_PF_type == 'PF_type6':\n",
    "        return Preference_Function_Type6(d)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e81dbcc8",
   "metadata": {},
   "source": [
    "### Define the LT_to_TFN function to convert the evaluation results of expert group to TFN values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "00892356",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Convert_LT_to_TNF(language_term_matrix):\n",
    "    '''\n",
    "    input:\n",
    "        language_term_matrix: language term assessment matrix provided by experts,\n",
    "                              size: n×m\n",
    "    output:\n",
    "        TNF_matrix_L: lower boundary of triangular fuzzy matrix\n",
    "        TNF_matrix_M: mean value of triangular fuzzy matrix\n",
    "        TNF_matrix_U: upper boundary of triangular fuzzy matrix\n",
    "    '''\n",
    "    language_term_table = {'VL': (0,0,0.25),\n",
    "                           'L':  (0,0.25,0.5),\n",
    "                           'M':  (0.25,0.5,0.75),\n",
    "                           'H':  (0.5,0.75,1.),\n",
    "                           'VH':  (0.75,1.,1.)}\n",
    "    TNF_matrix_L = np.zeros(language_term_matrix.shape)\n",
    "    TNF_matrix_M = np.zeros(language_term_matrix.shape)\n",
    "    TNF_matrix_U = np.zeros(language_term_matrix.shape)\n",
    "    for i in range(language_term_matrix.shape[0]):\n",
    "        for j in range(language_term_matrix.shape[1]):\n",
    "            value_ij = language_term_table[language_term_matrix[i][j]]\n",
    "            TNF_matrix_L[i][j] = value_ij[0]\n",
    "            TNF_matrix_M[i][j] = value_ij[1]\n",
    "            TNF_matrix_U[i][j] = value_ij[2]\n",
    "    return TNF_matrix_L, TNF_matrix_M, TNF_matrix_U"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "493d83ca",
   "metadata": {},
   "source": [
    "### Define the Fuzzy _PROMETHEE_II function to calculate the preference weight of expert group "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dffeee3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Fuzzy_PROMETHEE_II(A_L,A_M,A_U,C_PF_types,C_weights):\n",
    "    # the size of A_L/A_M/A_U: n×m×K\n",
    "    # S8.2. Calculate the expert group evaluation matrix\n",
    "    B_L = np.sum(A_L,axis=0)/A_L.shape[0]\n",
    "    B_M = np.sum(A_M,axis=0)/A_M.shape[0]\n",
    "    B_U = np.sum(A_U,axis=0)/A_U.shape[0]\n",
    "    \n",
    "    # S8.4. Calculate the preference index for each demand\n",
    "    '''\n",
    "    存储格式(n×(n-1))为：\n",
    "    a1-> a1,a2,...,an\n",
    "    a2-> a1,a2,...,an\n",
    "    ...\n",
    "    an-> a1,a2,...,an\n",
    "    '''\n",
    "    PI_L_plus = np.zeros((B_L.shape[0],B_L.shape[0]))\n",
    "    PI_L_minus = np.zeros((B_L.shape[0],B_L.shape[0]))\n",
    "    PI_M_plus = np.zeros((B_M.shape[0],B_M.shape[0]))\n",
    "    PI_M_minus = np.zeros((B_M.shape[0],B_M.shape[0]))\n",
    "    PI_U_plus = np.zeros((B_U.shape[0],B_U.shape[0]))\n",
    "    PI_U_minus = np.zeros((B_U.shape[0],B_U.shape[0]))\n",
    "    \n",
    "    for i in range(B_L.shape[0]):  # n行--取ai\n",
    "        for j in range(B_L.shape[0]):  # n行--取aj\n",
    "            if i == j:  #当ai==ai\n",
    "                PI_L_plus[i][j] = 0\n",
    "                PI_L_minus[i][j] = 0\n",
    "                PI_M_plus[i][j] = 0\n",
    "                PI_M_minus[i][j] = 0\n",
    "                PI_U_plus[i][j] = 0\n",
    "                PI_U_minus[i][j] = 0\n",
    "                continue\n",
    "            else: # 比较ai和aj\n",
    "                PI_L_plus_ai_aj = 0.\n",
    "                PI_L_minus_ai_aj = 0.\n",
    "                PI_M_plus_ai_aj = 0.\n",
    "                PI_M_minus_ai_aj = 0.\n",
    "                PI_U_plus_ai_aj = 0.\n",
    "                PI_U_minus_ai_aj = 0.\n",
    "                for m in range(B_L.shape[1]):  # 计算ai和aj在m项指标下\n",
    "                    # 获取准则cm的偏好函数\n",
    "                    cm_PF_type = C_PF_types[m]\n",
    "                    cm_weight = C_weights[m]\n",
    "                    # 计算ai和aj之间的偏好值下限\n",
    "                    ai_cm_L = B_L[i][m]  # value of ai_cm_L\n",
    "                    aj_cm_L = B_L[j][m]  # value of aj_cm_L\n",
    "                    ai_aj_L_plus = cm_weight * Calculate_PF(ai_cm_L - aj_cm_L, cm_PF_type)  # ai相对于aj的优势\n",
    "                    ai_aj_L_minus = cm_weight * Calculate_PF(aj_cm_L - ai_cm_L, cm_PF_type)  # ai相对于aj的劣势\n",
    "                    PI_L_plus_ai_aj += ai_aj_L_plus\n",
    "                    PI_L_minus_ai_aj += ai_aj_L_minus\n",
    "                    # 计算ai和aj之间的偏好值中值\n",
    "                    ai_cm_M = B_M[i][m]  # value of ai_cm_M\n",
    "                    aj_cm_M = B_M[j][m]  # value of aj_cm_M\n",
    "                    ai_aj_M_plus = cm_weight * Calculate_PF(ai_cm_M - aj_cm_M, cm_PF_type)  # ai相对于aj的优势\n",
    "                    ai_aj_M_minus = cm_weight * Calculate_PF(aj_cm_M - ai_cm_M, cm_PF_type)  # ai相对于aj的劣势\n",
    "                    PI_M_plus_ai_aj += ai_aj_M_plus\n",
    "                    PI_M_minus_ai_aj += ai_aj_M_minus\n",
    "                    # 计算ai和aj之间的偏好值上限\n",
    "                    ai_cm_U = B_U[i][m]  # value of ai_cm_U\n",
    "                    aj_cm_U = B_U[j][m]  # value of aj_cm_U\n",
    "                    ai_aj_U_plus = cm_weight * Calculate_PF(ai_cm_U - aj_cm_U, cm_PF_type)  # ai相对于aj的优势\n",
    "                    ai_aj_U_minus = cm_weight * Calculate_PF(aj_cm_U - ai_cm_U, cm_PF_type)  # ai相对于aj的劣势\n",
    "                    PI_U_plus_ai_aj += ai_aj_U_plus\n",
    "                    PI_U_minus_ai_aj += ai_aj_U_minus\n",
    "                # 添加到PI列表中\n",
    "                PI_L_plus[i][j] = PI_L_plus_ai_aj\n",
    "                PI_L_minus[i][j] =  PI_L_minus_ai_aj\n",
    "                PI_M_plus[i][j] = PI_M_plus_ai_aj\n",
    "                PI_M_minus[i][j] = PI_M_minus_ai_aj\n",
    "                PI_U_plus[i][j] = PI_U_plus_ai_aj\n",
    "                PI_U_minus[i][j] = PI_U_minus_ai_aj\n",
    "    \n",
    "    # S8.5. Calculate the input, output and net flows\n",
    "    # calculate the input and output flow\n",
    "    input_flow_L = np.sum(PI_L_plus, axis=1)\n",
    "    input_flow_M = np.sum(PI_M_plus, axis=1)\n",
    "    input_flow_U = np.sum(PI_U_plus, axis=1)\n",
    "    output_flow_L = np.sum(PI_L_minus, axis=1)\n",
    "    output_flow_M = np.sum(PI_M_minus, axis=1)\n",
    "    output_flow_U = np.sum(PI_U_minus, axis=1)\n",
    "    # Convert TNF to crisp value\n",
    "    input_flow = (input_flow_L + 2 * input_flow_M + input_flow_U)/4\n",
    "    output_flow = (output_flow_L + 2 * output_flow_M + output_flow_U)/4\n",
    "    # calculate the net flow\n",
    "    net_flow = input_flow - output_flow\n",
    "    #print(net_flow)\n",
    "    #print(np.argsort(net_flow)+1)\n",
    "    net_flow += B_L.shape[0]\n",
    "    # S8.6. Calculate expert preference weights based on net flows\n",
    "    sum_flow = np.sum(net_flow)\n",
    "    expert_preference_weights = np.around(net_flow/sum_flow,4)\n",
    "    return expert_preference_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b18d9e74",
   "metadata": {},
   "source": [
    "## Load the evaluation results of user  and calculate the preference weight of user "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f8bf2c5a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SR_Ex:\n",
      "[0.0431 0.0393 0.0431 0.0588 0.0633 0.082  0.0145 0.023  0.0154 0.0031\n",
      " 0.0116 0.0151 0.0165 0.0298 0.0332 0.029  0.02   0.0297 0.0097 0.0201\n",
      " 0.0342 0.0352 0.0546 0.0029 0.0434 0.0307]\n",
      "[ 6.  8.  7.  3.  2.  1. 22. 16. 20. 25. 23. 21. 19. 13. 11. 15. 18. 14.\n",
      " 24. 17. 10.  9.  4. 26.  5. 12.]\n",
      "SC_Ex:\n",
      "[0.0179 0.0199 0.0169 0.0096 0.0066 0.0024 0.0436 0.0324 0.0454 0.0767\n",
      " 0.0524 0.0425 0.0415 0.024  0.0217 0.026  0.0366 0.0249 0.0549 0.0363\n",
      " 0.021  0.0193 0.009  0.0795 0.0156 0.0249]\n",
      "[20. 18. 21. 23. 25. 26.  6. 11.  5.  2.  4.  7.  8. 15. 16. 12.  9. 13.\n",
      "  3. 10. 17. 19. 24.  1. 22. 14.]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\n# get the ranking of user preference weights obtained by different methods\\nweights_by_Cebi = weights_by_different_methods[0]\\nweights_by_Wang = weights_by_different_methods[1]\\nweights_by_Zhou = weights_by_different_methods[2]\\nweights_by_ours = weights_by_different_methods[3]\\ndef get_ranking(input_values):\\n    idx = np.argsort(-input_values)\\n    ranking = np.zeros(input_values.shape)\\n    for i in range(input_values.shape[0]):\\n        ranking[idx[i]] = i+1\\n    return ranking\\nranking_Cebi = get_ranking(weights_by_Cebi)\\nranking_Wang = get_ranking(weights_by_Wang)\\nranking_Zhou = get_ranking(weights_by_Zhou)\\nranking_ours = get_ranking(weights_by_ours)\\n\\n# Save user preference weights and ranking\\nheader = ['Cebi(2013)','ranking','Wang(2015)','ranking','Zhou et al.(2023)','ranking','Ours','ranking']\\nweights_rankings = np.array([weights_by_Cebi,ranking_Cebi,weights_by_Wang,ranking_Wang,weights_by_Zhou,ranking_Zhou,weights_by_ours,ranking_ours])\\ndf_weights_rankings = pd.DataFrame(weights_rankings.T)\\nwriter_weights_rankings = pd.ExcelWriter('preference weights and rankings of the new user obtained by different methods.xlsx')\\ndf_weights_rankings.to_excel(writer_weights_rankings,'weights and rankings',header=header,index=False,float_format='%.4f')\\nwriter_weights_rankings.save()\\nwriter_weights_rankings.close()\\n\\n# save only the preference weights of the new user\\nheader = ['Cebi(2013)','Wang(2015)','Zhou et al.(2023)','Ours']\\nweights = np.array([weights_by_Cebi,weights_by_Wang,weights_by_Zhou,weights_by_ours])\\ndf_weights = pd.DataFrame(weights.T)\\nwriter_weights = pd.ExcelWriter('preference weights of the new user obtained by different methods.xlsx')\\ndf_weights.to_excel(writer_weights,'weights',header=header,index=False,float_format='%.4f')\\nwriter_weights.save()\\nwriter_weights.close()\\n\\n# save only the ranking of weights\\nheader = ['ranking_by_Cebi(2013)','ranking_by_Wang(2015)','ranking_by_Zhou et al.(2023)','ranking_by_Ours']\\nrankings = np.array([ranking_Cebi,ranking_Wang,ranking_Zhou,ranking_ours])\\ndf_rankings = pd.DataFrame(rankings.T)\\nwriter_rankings = pd.ExcelWriter('the ranking of weights obtained by different methods.xlsx')\\ndf_rankings.to_excel(writer_rankings,'rankings',header=header,index=False)\\nwriter_rankings.save()\\nwriter_rankings.close()\\n\\n# print the preference weights and ranking obtained by our method\\nprint('='*60)\\nprint('User preference weights:')\\nprint(weights_by_ours)\\nprint('Ascending sort index of user preference weights:')\\nprint(ranking_ours)\\nprint('='*60)\\n\""
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# S7.1. Obtain the user assessment matrix\n",
    "file_path = './user evaluation results.xlsx'\n",
    "user_evaluation_data = pd.read_excel(file_path, index_col=0)\n",
    "user_evaluation_data_np = user_evaluation_data.to_numpy()\n",
    "\n",
    "# calculate user preference weights by Cloud_DEMATEL function\n",
    "PR_value,weights_by_different_methods = Cloud_DEMATEL(user_evaluation_data_np)\n",
    "\n",
    "# save P and R to excel file\n",
    "PR = np.array(PR_value)\n",
    "df_PR = pd.DataFrame(PR.T)\n",
    "writer_PR = pd.ExcelWriter('PR value.xlsx')\n",
    "df_PR.to_excel(writer_PR, 'PR value',float_format='%.4f',header=['P','R'],index=False)\n",
    "writer_PR.save()\n",
    "writer_PR.close()\n",
    "# get the ranking of user preference weights obtained by different methods\n",
    "weights_by_Cebi = weights_by_different_methods[0]\n",
    "weights_by_Wang = weights_by_different_methods[1]\n",
    "weights_by_Zhou = weights_by_different_methods[2]\n",
    "weights_by_ours = weights_by_different_methods[3]\n",
    "ranking_Cebi = get_ranking(weights_by_Cebi)\n",
    "ranking_Wang = get_ranking(weights_by_Wang)\n",
    "ranking_Zhou = get_ranking(weights_by_Zhou)\n",
    "ranking_ours = get_ranking(weights_by_ours)\n",
    "\n",
    "# Save user preference weights and ranking\n",
    "header = ['Cebi(2013)','ranking','Wang(2015)','ranking','Zhou et al.(2023)','ranking','Ours','ranking']\n",
    "weights_rankings = np.array([weights_by_Cebi,ranking_Cebi,weights_by_Wang,ranking_Wang,weights_by_Zhou,ranking_Zhou,weights_by_ours,ranking_ours])\n",
    "df_weights_rankings = pd.DataFrame(weights_rankings.T)\n",
    "writer_weights_rankings = pd.ExcelWriter('preference weights and rankings of the new user obtained by different methods.xlsx')\n",
    "df_weights_rankings.to_excel(writer_weights_rankings,'weights and rankings',header=header,index=False,float_format='%.4f')\n",
    "writer_weights_rankings.save()\n",
    "writer_weights_rankings.close()\n",
    "\n",
    "# save only the preference weights of the new user\n",
    "header = ['Cebi(2013)','Wang(2015)','Zhou et al.(2023)','Ours']\n",
    "weights = np.array([weights_by_Cebi,weights_by_Wang,weights_by_Zhou,weights_by_ours])\n",
    "df_weights = pd.DataFrame(weights.T)\n",
    "writer_weights = pd.ExcelWriter('preference weights of the new user obtained by different methods.xlsx')\n",
    "df_weights.to_excel(writer_weights,'weights',header=header,index=False,float_format='%.4f')\n",
    "writer_weights.save()\n",
    "writer_weights.close()\n",
    "\n",
    "# save only the ranking of weights\n",
    "header = ['ranking_by_Cebi(2013)','ranking_by_Wang(2015)','ranking_by_Zhou et al.(2023)','ranking_by_Ours']\n",
    "rankings = np.array([ranking_Cebi,ranking_Wang,ranking_Zhou,ranking_ours])\n",
    "df_rankings = pd.DataFrame(rankings.T)\n",
    "writer_rankings = pd.ExcelWriter('the ranking of weights obtained by different methods.xlsx')\n",
    "df_rankings.to_excel(writer_rankings,'rankings',header=header,index=False)\n",
    "writer_rankings.save()\n",
    "writer_rankings.close()\n",
    "\n",
    "# print the preference weights and ranking obtained by our method\n",
    "print('='*60)\n",
    "print('User preference weights:')\n",
    "print(weights_by_ours)\n",
    "print('Ascending sort index of user preference weights:')\n",
    "print(ranking_ours)\n",
    "print('='*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98c82abc",
   "metadata": {},
   "source": [
    "## Load the  evaluation results of expert group and calculate the preference weight of expert group "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a1eb15f4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The preference weights of expert\n",
      "[0.0423 0.0542 0.0433 0.0386 0.0466 0.0518 0.034  0.0361 0.0401 0.0336\n",
      " 0.0306 0.0373 0.035  0.0341 0.0481 0.0411 0.0349 0.0403 0.0289 0.0455\n",
      " 0.0224 0.0347 0.0442 0.0274 0.0389 0.0359]\n",
      "Rankings:\n",
      "[ 8.  1.  7. 13.  4.  2. 21. 15. 11. 22. 23. 14. 17. 20.  3.  9. 18. 10.\n",
      " 24.  5. 26. 19.  6. 25. 12. 16.]\n"
     ]
    }
   ],
   "source": [
    "# S8.1. Obtain (Load) the evaluation results for each expert\n",
    "expert_1 = pd.read_excel('./expert group evaluation results.xlsx',sheet_name = 'expert_1',index_col=0)\n",
    "expert_2 = pd.read_excel('./expert group evaluation results.xlsx',sheet_name = 'expert_2',index_col=0)\n",
    "expert_3 = pd.read_excel('./expert group evaluation results.xlsx',sheet_name = 'expert_3',index_col=0)\n",
    "\n",
    "# Convert expert evaluation lingustic term to TNF\n",
    "expert_1_L,expert_1_M,expert_1_U = Convert_LT_to_TNF(expert_1.to_numpy())\n",
    "expert_2_L,expert_2_M,expert_2_U = Convert_LT_to_TNF(expert_1.to_numpy())\n",
    "expert_3_L,expert_3_M,expert_3_U = Convert_LT_to_TNF(expert_1.to_numpy())\n",
    "expert_group_L = np.array([expert_1_L, expert_2_L, expert_3_L])\n",
    "expert_group_M = np.array([expert_1_M, expert_2_M, expert_3_M])\n",
    "expert_group_U = np.array([expert_1_U, expert_2_U, expert_3_U])\n",
    "\n",
    "# S8.3. Determine the preference function for each criterion and the weights of expert\n",
    "E_PF_types = ['PF_type1','PF_type6','PF_type6','PF_type3','PF_type4','PF_type1','PF_type3','PF_type3']\n",
    "E_weights = np.array([0.15,0.15,0.15,0.15,0.05,0.1,0.15,0.1])\n",
    "\n",
    "# Calculate expert preference weights by Fuzzy_PROMETHEE_II function\n",
    "preference_weights_by_expert = Fuzzy_PROMETHEE_II(expert_group_L,expert_group_M,expert_group_U,E_PF_types,E_weights)\n",
    "\n",
    "# Save the preference weights and rankings of experts\n",
    "rankings_expert = get_ranking(preference_weights_by_expert)\n",
    "weights_rankings_expert = np.array([preference_weights_by_expert,rankings_expert])\n",
    "df_weights_rankings_expert = pd.DataFrame(weights_rankings_expert.T)\n",
    "writer_expert = pd.ExcelWriter('the preference weights and rankings of expert.xlsx')\n",
    "df_weights_rankings_expert.to_excel(writer_expert,'weights and ranking',header=['weights','ranking'],index=None)\n",
    "writer_expert.save()\n",
    "writer_expert.close()\n",
    "\n",
    "# print the preference weights and rankings of experts\n",
    "print('The preference weights of expert')\n",
    "print(preference_weights_by_expert)\n",
    "print('Rankings:')\n",
    "print(rankings_expert)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1b3739f",
   "metadata": {},
   "source": [
    "## Calculate the combined preference weights and sort user requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3096882a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined preference weights:\n",
      "[0.04805 0.05165 0.04855 0.056   0.0628  0.07705 0.026   0.0324  0.02965\n",
      " 0.01875 0.02255 0.0281  0.0278  0.03565 0.04475 0.0387  0.02995 0.0387\n",
      " 0.0205  0.0353  0.03255 0.0393  0.05615 0.0155  0.04655 0.0371 ]\n",
      "Ranking of the combined preference weights:\n",
      "[ 7.  5.  6.  4.  2.  1. 22. 17. 19. 25. 23. 20. 21. 14.  9. 12. 18. 11.\n",
      " 24. 15. 16. 10.  3. 26.  8. 13.]\n"
     ]
    }
   ],
   "source": [
    "# S9. calculate the combined preference weights\n",
    "alpha = 0.5\n",
    "combined_weights_05 = alpha * weights_by_ours + (1-alpha) * preference_weights_by_expert\n",
    "# Sort user requirements according to W\n",
    "ranking_combined_weights_05 = get_ranking(combined_weights_05)\n",
    "\n",
    "# Save the combined preference weights and ranking\n",
    "combined_weights_ranking = np.array([combined_weights_05,ranking_combined_weights_05])\n",
    "df_combined = pd.DataFrame(combined_weights_ranking.T)\n",
    "writer_combined = pd.ExcelWriter('The combined preference weights and ranking.xlsx')\n",
    "df_combined.to_excel(writer_combined,'combined weights and ranking',header=['combined preference weight','ranking'],index=None)\n",
    "writer_combined.save()\n",
    "writer_combined.close()\n",
    "\n",
    "# print the preference weight and ranking\n",
    "print('Combined preference weights:')\n",
    "print(combined_weights_05)\n",
    "print('Ranking of the combined preference weights:')\n",
    "print(ranking_combined_weights_05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1455f31c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finish!\n"
     ]
    }
   ],
   "source": [
    "# Compare the combined preference weights and rankings for different preference reconciliation parameters\n",
    "alphas = [0.0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1.0]\n",
    "results_weights = []\n",
    "results_rankings = []\n",
    "results_weights_ranking = []\n",
    "header_weights = []\n",
    "header_rankings = []\n",
    "header_weights_ranking = []\n",
    "for i in range(len(alphas)):\n",
    "    alpha_i = alphas[i]\n",
    "    header_weights.append('alpha=' + str(alpha_i))\n",
    "    header_rankings.append('ranking ' + '(alpha=' + str(alpha_i) + ')')\n",
    "    header_weights_ranking.append('alpha=' + str(alpha_i))\n",
    "    header_weights_ranking.append('ranking ' + '(alpha=' + str(alpha_i) + ')')\n",
    "    # calculate the combined preference weights when alpha equals alpha_i\n",
    "    combined_weights_i = alpha_i * weights_by_ours + (1-alpha_i) * preference_weights_by_expert\n",
    "    ranking_combined_weights_i = get_ranking(combined_weights_i)\n",
    "    results_weights.append(np.array(combined_weights_i))\n",
    "    results_rankings.append(np.array(ranking_combined_weights_i))\n",
    "    results_weights_ranking.append(np.array(combined_weights_i))\n",
    "    results_weights_ranking.append(np.array(ranking_combined_weights_i))\n",
    "# Save only the results of combined weights\n",
    "df_results_weights = pd.DataFrame(np.array(results_weights).T)\n",
    "df_results_weights_writer = pd.ExcelWriter('results of combined preference weights with different alpha values.xlsx')\n",
    "df_results_weights.to_excel(df_results_weights_writer,'combined weights',header=header_weights,index=False)\n",
    "df_results_weights_writer.save()\n",
    "df_results_weights_writer.close()\n",
    "# Save only the results of rankings\n",
    "df_results_rankings = pd.DataFrame(np.array(results_rankings).T)\n",
    "df_results_rankings_writer = pd.ExcelWriter('results of the rankings of combined preference weights with different alpha values.xlsx')\n",
    "df_results_rankings.to_excel(df_results_rankings_writer,'rankings',header=header_rankings,index=False)\n",
    "df_results_rankings_writer.save()\n",
    "df_results_rankings_writer.close()\n",
    "# Save the combined weights and ranking\n",
    "df_results_weights_rankings = pd.DataFrame(np.array(results_weights_ranking).T)\n",
    "df_results_weights_rankings_writer = pd.ExcelWriter('results of the combined preference weights and rankings with different alpha values.xlsx')\n",
    "df_results_weights_rankings.to_excel(df_results_weights_rankings_writer, 'combined weights and rankings', header=header_weights_ranking, index=False)\n",
    "df_results_weights_rankings_writer.save()\n",
    "df_results_weights_rankings_writer.close()\n",
    "print('Finish!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eb7c1ac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
